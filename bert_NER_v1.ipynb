{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of  bert version 1.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSPWW0RyxHh_"
      },
      "source": [
        "# **1 Import and installations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vX74bNmAbZh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c347062-37d6-423a-cd61-2ddfc3186f21"
      },
      "source": [
        "!pip install bert-tensorflow\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/16/0f9376af49c6adcfbaf2470a8f500105a74dd803aa54ac0110af445837b5/bert_tensorflow-1.0.4-py2.py3-none-any.whl (64kB)\n",
            "\r\u001b[K     |█████                           | 10kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30kB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 61kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from bert-tensorflow) (1.15.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HYqADFL6Zz9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f43c2509-70ea-4bfc-e95c-da8bf45b5171"
      },
      "source": [
        "pip install pytorch-pretrained-bert\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 14.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.19.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.17.70)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.4.2)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.70 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (1.20.70)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.70->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.70->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPiOohjpxGmZ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1K9YNSD8qgoe",
        "outputId": "b0407920-3f59-472a-f9cd-773b1b88b6aa"
      },
      "source": [
        "pip install seqeval\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\r\u001b[K     |███████▌                        | 10kB 14.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 19.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30kB 10.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16172 sha256=ef098a01bed18323b8bc32e3f02601699f7464ff9a11d7c34eeee7bc488456fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuL6JTjtq-BT"
      },
      "source": [
        "pip install tensorflow-hub\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7HB-CBCq_oo"
      },
      "source": [
        "pip install tensorflow\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqgY8609aakS"
      },
      "source": [
        "!pip install pytorch-transformers\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzkxrlaKrBBV"
      },
      "source": [
        "pip install tensorflow-gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf1AN0ELHdbh"
      },
      "source": [
        "import bert\n",
        "from bert import tokenization\n",
        "from tqdm import tqdm, trange\n",
        "import tensorflow as tf\n",
        "from torch.autograd import Variable\n",
        "##\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig , BertModel\n",
        "from pytorch_pretrained_bert import BertForTokenClassification, BertAdam\n",
        "import itertools\n",
        "from seqeval.metrics import f1_score\n",
        "# from bert import run_classifier\n",
        "# from bert import optimization\n",
        "# from bert import tokenization\n",
        "tf.config.experimental.list_physical_devices('GPU')\n",
        "#group in sentences\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow_hub as hub\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Puw82CFMxmub"
      },
      "source": [
        "# **2 Constants**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knfoNum7xtWb"
      },
      "source": [
        "MAX_LEN = 75\n",
        "BATCH_SIZE = 32\n",
        "LABEL_LIST = ['B-LOC', 'I-PER', 'B-MISC', 'I-ORG', 'I-MISC','B-ORG', 'O','I-LOC']\n",
        "EPOCHS = 3\n",
        "EN = 'en'\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnbidJn3x0hK"
      },
      "source": [
        "# **3 Functions**\n",
        "> data pre-processing \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM8PyyE_Li9K"
      },
      "source": [
        "\n",
        "\n",
        "def dataPreprocessing(path):\n",
        "  '''\n",
        "  function which takes an input file for bert and process it.\n",
        "  @param path - path to the dataset\n",
        "  returns - \n",
        "  sentences create senctence from data,\n",
        "  labels - label of each sentence \n",
        "    \n",
        "    O - Outside of a named entity\n",
        "    B-MIS -  Beginning of a miscellaneous entity right after another miscellaneous entity\n",
        "    I-MIS  - Miscellaneous entity \n",
        "    B-PER - Beginning of a person’s name right after another person’s name\n",
        "    I-PER  - Person’s name \n",
        "    B-ORG - Beginning of an organisation right after another organisation \n",
        "    I-ORG - Organisation \n",
        "    B-LOC - Beginning of a location right after another location\n",
        "    I-LOC - Location\n",
        "    location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC).\n",
        "  tags_vals - all optional tags. ['I-PER', 'I-MISC', 'B-ORG', 'B-MISC', 'I-ORG', 'B-LOC', 'O', 'I-LOC']\n",
        "  tags2idx - dictionary with value for each tag - example :\n",
        "    {I-PER: 1, 'I-MISC': 2, 'B-ORG': 3, 'B-MISC': 4, 'I-ORG': 5, 'B-LOC': 6, 'O': 7, 'I-LOC': 8}\n",
        "  tag_count - count appreances of each tag\n",
        "  data - data frame with entire data \n",
        "    [index', 'Word', 'POS', 'Sentence#', 'Tag', 'fullSentence']\n",
        "  getter.sentences - sentence iterator\n",
        "  \n",
        "  '''\n",
        "  data = pd.read_csv(path,sep = \" \").fillna(0)\n",
        "  data.columns = ['Word', 'POS','Sentence#','Tag']\n",
        "  #remove O - not intersting\n",
        "  data = data[data[\"POS\"] != 'O']\n",
        "  data = data.reset_index()\n",
        "  #get all end of sentence indexs\n",
        "  sentence_sep = np.insert(data.index[data['POS'] == '.']+1,0,0)\n",
        "  # length of sentences\n",
        "  ranges = np.insert(np.asarray(sentence_sep[1:] - sentence_sep[:-1]),len(sentence_sep)-1,data.shape[0]-sentence_sep[-1])# for i in range(len(ranges)):\n",
        "\n",
        "  # succsessive id for number of sentence we are at (0,0,0,1,1,1,1,2,2,2,2,..)\n",
        "  sentenceNum = list(itertools.chain.from_iterable(itertools.repeat(x,r) for x,r in zip(range(len(ranges)),ranges)))\n",
        "  # inner enumeration of each sentence (0,1,2,0,1,2,3,0,1,2,3...)\n",
        "  innerPos = list(itertools.chain.from_iterable(range(r) for x,r in zip(range(len(ranges)),ranges)))\n",
        "  data[\"POS\"] = innerPos\n",
        "  data[\"Sentence#\"] = sentenceNum\n",
        "\n",
        "\n",
        "  #iterator of sentences\n",
        "  getter = SentenceGetter(data)\n",
        "\n",
        "  sentences = [\" \".join([str(s[0]) for s in sent]) for sent in getter.sentences]\n",
        "  labels = [[s[2] for s in sent] for sent in getter.sentences]\n",
        "  \n",
        "  data[\"fullSentence\"] = list(itertools.chain.from_iterable(itertools.repeat(x,r) for x,r in zip(sentences,ranges)))\n",
        "  data[\"fullSentenceTag\"] = list(itertools.chain.from_iterable(itertools.repeat(x,r) for x,r in zip(labels,ranges)))\n",
        "\n",
        "  segments = [[\"0\" for s in sent] for sent in sentences]\n",
        "\n",
        "  # labels = [lab+[\"[SE for lab in labels]\n",
        "  # sentences = [\"[CLS]\"+sen+\"[SEP]\" for sen in sentences]\n",
        "  #contains all tages\n",
        "  tags_vals = list(set(data[\"Tag\"].values))\n",
        "  # contains a dictionary of the tags - each enumerated \n",
        "  tag2idx = {t: i+1 for i, t in enumerate(tags_vals)}\n",
        "  tag_count = {}\n",
        "  for label in tags_vals:\n",
        "      tag_count[label] = len(data.index[data['Tag'] == label])\n",
        "  \n",
        "  return sentences,labels,tags_vals,tag2idx,tag_count,data,getter.sentences\n",
        "\n",
        "\n",
        "class SentenceGetter(object):\n",
        "  '''\n",
        "  generate a sentence iterator\n",
        "  each return yields 3 different lists : word,POS,tag which \n",
        "  correspond to each other\n",
        "  '''\n",
        "\n",
        "  def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
        "                                                           s[\"POS\"].values.tolist(),\n",
        "                                                           s[\"Tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"Sentence#\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "\n",
        "  def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[self.n_sent]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRT3CAX4Tut5"
      },
      "source": [
        "Initialize model and set the set model hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baf8fCaoTtl3"
      },
      "source": [
        "def get_hyperparameters(model, ff):\n",
        "\n",
        "    # ff: full_finetuning\n",
        "    if ff:\n",
        "        param_optimizer = list(model.named_parameters())\n",
        "        no_decay = [\"bias\", \"gamma\", \"beta\"]\n",
        "        optimizer_grouped_parameters = [\n",
        "            {\n",
        "                \"params\": [\n",
        "                    p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
        "                ],\n",
        "                \"weight_decay_rate\": 0.01,\n",
        "            },\n",
        "            {\n",
        "                \"params\": [\n",
        "                    p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
        "                ],\n",
        "                \"weight_decay_rate\": 0.0,\n",
        "            },\n",
        "        ]\n",
        "    else:\n",
        "        param_optimizer = list(model.classifier.named_parameters())\n",
        "        optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "\n",
        "    return optimizer_grouped_parameters\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfnT_GmEUUNR"
      },
      "source": [
        "train model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_4CHtOHURMK"
      },
      "source": [
        "def train_and_save_model(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    optimizer,\n",
        "    idx2tag,\n",
        "    tag2idx,\n",
        "    this_run,\n",
        "    max_grad_norm,\n",
        "    device,\n",
        "    train_dataloader,\n",
        "    valid_dataloader,\n",
        "):\n",
        "\n",
        "    pad_tok, sep_tok, cls_tok, o_lab = get_special_tokens(tokenizer, tag2idx)\n",
        "    verbose = True\n",
        "    epochs = EPOCHS\n",
        "\n",
        "    epoch = 0\n",
        "    for _ in trange(epochs, desc=\"Epoch\"):\n",
        "        epoch += 1\n",
        "\n",
        "        # Training loop\n",
        "        print(\"Starting training loop.\")\n",
        "        model.train()\n",
        "        tr_loss, tr_accuracy = 0, 0\n",
        "        nb_tr_examples, nb_tr_steps = 0, 0\n",
        "        tr_preds, tr_labels = [], []\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            # Add batch to gpu\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(\n",
        "                b_input_ids,\n",
        "                token_type_ids=None,\n",
        "                attention_mask=b_input_mask,\n",
        "                labels=b_labels,\n",
        "            )\n",
        "            loss, tr_logits = outputs[:2]\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "\n",
        "            # Compute train loss\n",
        "            tr_loss += loss.item()\n",
        "            nb_tr_examples += b_input_ids.size(0)\n",
        "            nb_tr_steps += 1\n",
        "\n",
        "            # Subset out unwanted predictions on CLS/PAD/SEP tokens\n",
        "            preds_mask = (\n",
        "                (b_input_ids != cls_tok)\n",
        "                & (b_input_ids != pad_tok)\n",
        "                & (b_input_ids != sep_tok)\n",
        "            )\n",
        "\n",
        "            tr_logits = tr_logits.detach().cpu().numpy()\n",
        "            tr_label_ids = torch.masked_select(b_labels, (preds_mask == 1))\n",
        "            tr_batch_preds = np.argmax(tr_logits[preds_mask.squeeze()], axis=1)\n",
        "            tr_batch_labels = tr_label_ids.to(\"cpu\").numpy()\n",
        "            tr_preds.extend(tr_batch_preds)\n",
        "            tr_labels.extend(tr_batch_labels)\n",
        "\n",
        "            # Compute training accuracy\n",
        "            tmp_tr_accuracy = accuracy_score(tr_batch_labels, tr_batch_preds)\n",
        "            tr_accuracy += tmp_tr_accuracy\n",
        "\n",
        "            # Gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(\n",
        "                parameters=model.parameters(), max_norm=max_grad_norm\n",
        "            )\n",
        "\n",
        "            # Update parameters\n",
        "            optimizer.step()\n",
        "            model.zero_grad()\n",
        "\n",
        "        tr_loss = tr_loss / nb_tr_steps\n",
        "        tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "\n",
        "        # Print training loss and accuracy per epoch\n",
        "        print(f\"Train loss: {tr_loss}\")\n",
        "        print(f\"Train accuracy: {tr_accuracy}\")\n",
        "\n",
        "        # Validation loop\n",
        "        print(\"Starting validation loop.\")\n",
        "\n",
        "        model.eval()\n",
        "        eval_loss, eval_accuracy = 0, 0\n",
        "        nb_eval_steps, nb_eval_examples = 0, 0\n",
        "        predictions, true_labels = [], []\n",
        "\n",
        "        for batch in valid_dataloader:\n",
        "\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(\n",
        "                    b_input_ids,\n",
        "                    token_type_ids=None,\n",
        "                    attention_mask=b_input_mask,\n",
        "                    labels=b_labels,\n",
        "                )\n",
        "                tmp_eval_loss, logits = outputs[:2]\n",
        "\n",
        "            # Subset out unwanted predictions on CLS/PAD/SEP tokens\n",
        "            preds_mask = (\n",
        "                (b_input_ids != cls_tok)\n",
        "                & (b_input_ids != pad_tok)\n",
        "                & (b_input_ids != sep_tok)\n",
        "            )\n",
        "\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = torch.masked_select(b_labels, (preds_mask == 1))\n",
        "            val_batch_preds = np.argmax(logits[preds_mask.squeeze()], axis=1)\n",
        "            val_batch_labels = label_ids.to(\"cpu\").numpy()\n",
        "            predictions.extend(val_batch_preds)\n",
        "            true_labels.extend(val_batch_labels)\n",
        "\n",
        "            tmp_eval_accuracy = flat_accuracy(val_batch_labels, val_batch_preds)\n",
        "\n",
        "            eval_loss += tmp_eval_loss.mean().item()\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "            nb_eval_examples += b_input_ids.size(0)\n",
        "            nb_eval_steps += 1\n",
        "\n",
        "        # Evaluate loss, acc, conf. matrix, and class. report on devset\n",
        "        pred_tags = [idx2tag[i] for i in predictions]\n",
        "        valid_tags = [idx2tag[i] for i in true_labels]\n",
        "        cl_report = classification_report(valid_tags, pred_tags)\n",
        "        conf_mat = annot_confusion_matrix(valid_tags, pred_tags)\n",
        "        eval_loss = eval_loss / nb_eval_steps\n",
        "        eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "\n",
        "        # Report metrics\n",
        "        print(f\"Validation loss: {eval_loss}\")\n",
        "        print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "        print(f\"Classification Report:\\n {cl_report}\")\n",
        "        if verbose:\n",
        "            print(f\"Confusion Matrix:\\n {conf_mat}\")\n",
        "\n",
        "        # Save model and optimizer state_dict following every epoch\n",
        "        save_path = f\"../models/{this_run}/train_checkpoint_epoch_{epoch}.tar\"\n",
        "        torch.save(\n",
        "            {\n",
        "                \"epoch\": epoch,\n",
        "                \"model_state_dict\": model.state_dict(),\n",
        "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "                \"train_loss\": tr_loss,\n",
        "                \"train_acc\": tr_accuracy,\n",
        "                \"eval_loss\": eval_loss,\n",
        "                \"eval_acc\": eval_accuracy,\n",
        "                \"classification_report\": cl_report,\n",
        "                \"confusion_matrix\": conf_mat,\n",
        "            },\n",
        "            save_path,\n",
        "        )\n",
        "        print(f\"Checkpoint saved to {save_path}.\")"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diM5W4sAZb8Y"
      },
      "source": [
        "def get_special_tokens(tokenizer, tag2idx):\n",
        "\n",
        "    pad_tok = tokenizer.vocab[\"[PAD]\"]\n",
        "    sep_tok = tokenizer.vocab[\"[SEP]\"]\n",
        "    cls_tok = tokenizer.vocab[\"[CLS]\"]\n",
        "    o_lab = tag2idx[\"O\"]\n",
        "\n",
        "    return pad_tok, sep_tok, cls_tok, o_lab"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiaaD-zdyQdx"
      },
      "source": [
        "mount collab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-CJpgmva5p3",
        "outputId": "353fad2b-6eda-457b-e113-f0c48baae836"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cs62_HLBziLL"
      },
      "source": [
        "# **4 Preprocess data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4DVSs2m0dH5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZK2ixRg0Qwg"
      },
      "source": [
        "## 4.1 Get input file and extract sentences, labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBWSGlrxbtAd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fe43636-16c8-49d7-b6a7-92a40c0e1074"
      },
      "source": [
        "train_sentences,train_labels,tags_vals,tag2idx,tag_count,train_data,sentences = dataPreprocessing(\"sample_data/eng.train.csv\")\n",
        "test_sentences,test_labels,_,_,_,test_data,_ = dataPreprocessing(\"sample_data/eng.testa.csv\")\n",
        "\n",
        "train_sentences= train_sentences[:1000]\n",
        "train_labels = train_labels[:1000]\n",
        "test_sentences = test_sentences[:200]\n",
        "test_labels = test_labels[:200]\n",
        "print(tag_count)\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'B-ORG': 24, 'I-PER': 11128, 'B-LOC': 11, 'B-MISC': 37, 'I-MISC': 4556, 'I-ORG': 10001, 'I-LOC': 8286, 'O': 168345}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "RT2O0RLa9LMf",
        "outputId": "1269effa-ecf6-4936-b691-ec388ef7a3c9"
      },
      "source": [
        "train_data.head(10)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Sentence#</th>\n",
              "      <th>Tag</th>\n",
              "      <th>fullSentence</th>\n",
              "      <th>fullSentenceTag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>EU</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>I-ORG</td>\n",
              "      <td>EU rejects German call to boycott British lamb .</td>\n",
              "      <td>[I-ORG, O, I-MISC, O, O, O, I-MISC, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>rejects</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>O</td>\n",
              "      <td>EU rejects German call to boycott British lamb .</td>\n",
              "      <td>[I-ORG, O, I-MISC, O, O, O, I-MISC, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>German</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>I-MISC</td>\n",
              "      <td>EU rejects German call to boycott British lamb .</td>\n",
              "      <td>[I-ORG, O, I-MISC, O, O, O, I-MISC, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>call</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>O</td>\n",
              "      <td>EU rejects German call to boycott British lamb .</td>\n",
              "      <td>[I-ORG, O, I-MISC, O, O, O, I-MISC, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>to</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>O</td>\n",
              "      <td>EU rejects German call to boycott British lamb .</td>\n",
              "      <td>[I-ORG, O, I-MISC, O, O, O, I-MISC, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>boycott</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>O</td>\n",
              "      <td>EU rejects German call to boycott British lamb .</td>\n",
              "      <td>[I-ORG, O, I-MISC, O, O, O, I-MISC, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>British</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>I-MISC</td>\n",
              "      <td>EU rejects German call to boycott British lamb .</td>\n",
              "      <td>[I-ORG, O, I-MISC, O, O, O, I-MISC, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>lamb</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>O</td>\n",
              "      <td>EU rejects German call to boycott British lamb .</td>\n",
              "      <td>[I-ORG, O, I-MISC, O, O, O, I-MISC, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>.</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>O</td>\n",
              "      <td>EU rejects German call to boycott British lamb .</td>\n",
              "      <td>[I-ORG, O, I-MISC, O, O, O, I-MISC, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>Peter</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>I-PER</td>\n",
              "      <td>Peter Blackburn BRUSSELS 1996-08-22 The Europe...</td>\n",
              "      <td>[I-PER, I-PER, I-LOC, O, O, I-ORG, I-ORG, O, O...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ...                                    fullSentenceTag\n",
              "0      0  ...          [I-ORG, O, I-MISC, O, O, O, I-MISC, O, O]\n",
              "1      1  ...          [I-ORG, O, I-MISC, O, O, O, I-MISC, O, O]\n",
              "2      2  ...          [I-ORG, O, I-MISC, O, O, O, I-MISC, O, O]\n",
              "3      3  ...          [I-ORG, O, I-MISC, O, O, O, I-MISC, O, O]\n",
              "4      4  ...          [I-ORG, O, I-MISC, O, O, O, I-MISC, O, O]\n",
              "5      5  ...          [I-ORG, O, I-MISC, O, O, O, I-MISC, O, O]\n",
              "6      6  ...          [I-ORG, O, I-MISC, O, O, O, I-MISC, O, O]\n",
              "7      7  ...          [I-ORG, O, I-MISC, O, O, O, I-MISC, O, O]\n",
              "8      8  ...          [I-ORG, O, I-MISC, O, O, O, I-MISC, O, O]\n",
              "9      9  ...  [I-PER, I-PER, I-LOC, O, O, I-ORG, I-ORG, O, O...\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TPXKxsPB5zu5",
        "outputId": "4dce2201-3768-486f-91ec-613c43712646"
      },
      "source": [
        "train_sentences[0]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'EU rejects German call to boycott British lamb .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kC0_bsCZ68Dw",
        "outputId": "3ca4d573-b8d6-4324-a342-b6d99ba35b90"
      },
      "source": [
        "train_labels[0]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I-ORG', 'O', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'O', 'O']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gss0N93g0m0b"
      },
      "source": [
        "## 4.2 Embed the data\n",
        "Adding pos of word as part of the sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFaNjIIfb2KI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "22ca8202-5ec3-4f15-cc90-896d798d90d3"
      },
      "source": [
        "#tokenize the senctence to a form bert will understand - \n",
        "#uncased: it does not make a difference between english and English.\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "# tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "#tokenize each sentence for all its words ##ing\n",
        "train_data_em  = [str(train_data[\"Word\"].iloc[i])+\" \"+str(train_data[\"POS\"].iloc[i])+\" \"\n",
        "                 +str(train_data[\"fullSentence\"].iloc[i]) for i in range(train_data.shape[0])]\n",
        "\n",
        "train_data_em[0]\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 231508/231508 [00:00<00:00, 3424444.48B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'EU 0 EU rejects German call to boycott British lamb .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhjZCzFj7NSB"
      },
      "source": [
        "train_tag_em  = [str(train_data[\"Tag\"].iloc[i])+\" \"+'O'+\" \"\n",
        "                 +\" \".join(train_data[\"fullSentenceTag\"].iloc[i]) for i in range(train_data.shape[0])]\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dCzmXbe0_Kmb",
        "outputId": "8107f786-23d6-4463-baf7-b0ea18c142a3"
      },
      "source": [
        "train_tag_em[0]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I-ORG O I-ORG O I-MISC O O O I-MISC O O'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eLjEMb6A1QzX",
        "outputId": "ef7550b2-7e79-4646-e349-d38fe433af57"
      },
      "source": [
        "test_data_em = [str(test_data[\"Word\"].iloc[i])+\" \"+str(test_data[\"POS\"].iloc[i])+\" \"\n",
        "                 +str(test_data[\"fullSentence\"].iloc[i]) for i in range(test_data.shape[0])]\n",
        "\n",
        "test_data_em[0]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'CRICKET 0 CRICKET - LEICESTERSHIRE TAKE OVER AT TOP AFTER INNINGS VICTORY .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3NRtpe6_2wJ"
      },
      "source": [
        "test_tag_em  = [str(test_data[\"Tag\"].iloc[i])+\" \"+'O'+\" \"\n",
        "                 +\" \".join(test_data[\"fullSentenceTag\"].iloc[i]) for i in range(test_data.shape[0])]\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Xdr5T73-_8jT",
        "outputId": "4034a81a-b30a-4182-f9f3-f4197bf1975c"
      },
      "source": [
        "test_tag_em[0]\n",
        "\n",
        "# [str(sen).split(\" \") for sen in train_tag_em][0]\n",
        "# str(train_tag_em[0])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'O O O O I-ORG O O O O O O O O'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOyKjLtG3uPF"
      },
      "source": [
        "## 4.3 Tokenize each sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_h_4p5j1ZwW",
        "outputId": "0d84e591-a641-4fe7-af3a-fa09282cb5db"
      },
      "source": [
        "'''\n",
        "lower case all and insert to an array\n",
        "example (2 is the place of german in the sentence)\n",
        "['german', '2', 'eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.']\n",
        "German 2 EU rejects German call to boycott British lamb .\n",
        "'''\n",
        "train_tokens = [tokenizer.tokenize(sent) for sent in train_data_em]\n",
        "test_tokens = [tokenizer.tokenize(sent) for sent in test_data_em]\n",
        "\n",
        "train_tag_tokens = [sen.split(\" \") for sen in train_tag_em]\n",
        "test_tag_tokens = [sen.split(\" \") for sen in test_tag_em]\n",
        "\n",
        "print(train_tokens[0])\n",
        "print(test_tokens[0])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['eu', '0', 'eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.']\n",
            "['cricket', '0', 'cricket', '-', 'leicestershire', 'take', 'over', 'at', 'top', 'after', 'innings', 'victory', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9lDzoaeKfz_"
      },
      "source": [
        "## 4.4 Convert to wordpiece ids + extract MAX_LEN sentences (padd)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ihftJLC6_ws"
      },
      "source": [
        "'''\n",
        "convert the words to word2vec encode\n",
        "example array([ 7327,  1014,  7327, 19164,  2446,  2655,  2000, 17757,  2329,\n",
        "       12559,  1012,     0,     0,     0,     0,     0,     0,     0,\n",
        "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "           0,     0,     0])\n",
        "'''\n",
        "train_tokens_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt[:512]) for txt in train_tokens],\n",
        "                           maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "test_tokens_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt[:512]) for txt in test_tokens],\n",
        "                           maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBtphjRhUhq1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ab5c235-e4f6-4120-b24b-3a9f81c037a2"
      },
      "source": [
        "# test_labels = [str(var) for var in test_data[\"Tag\"]]\n",
        "# train_labels = [str(var) for var in train_data[\"Tag\"]]\n",
        "print(f'number of train sentences {len(train_tokens_ids)}  number of train labels {len(train_tag_tokens)}')\n",
        "print(f'number of test sentences {len(test_tokens_ids)}  number of test labels {len(test_tag_tokens)}')\n",
        "\n",
        "\n",
        "train_tag_ids = pad_sequences([[tag2idx.get(l) for l in lab] for lab in train_tag_tokens],\n",
        "                     maxlen=MAX_LEN, value=tag2idx[\"O\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")\n",
        "\n",
        "test_tag_ids = pad_sequences([[tag2idx.get(l) for l in lab] for lab in test_tag_tokens],\n",
        "                     maxlen=MAX_LEN, value=tag2idx[\"O\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of train sentences 202388  number of train labels 202388\n",
            "number of test sentences 50937  number of test labels 50937\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JTEtSaJTcXB"
      },
      "source": [
        "## 4.5 Convert data to tensors and load tensors into DataLoaders "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUvtgSFpSoJl"
      },
      "source": [
        "train_attn_masks = [[float(i > 0) for i in ii] for ii in train_tokens_ids]\n",
        "test_attn_masks = [[float(i > 0) for i in ii] for ii in test_tokens_ids]\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMme5pqO_5o2"
      },
      "source": [
        "#create a sample of words which we will MASK\n",
        "tr_inputs = torch.tensor(train_tokens_ids)\n",
        "val_inputs = torch.tensor(test_tokens_ids)\n",
        "tr_tags = torch.tensor(train_tag_ids)\n",
        "val_tags = torch.tensor(test_tag_ids)\n",
        "tr_masks = torch.tensor(train_attn_masks)\n",
        "val_masks = torch.tensor(test_attn_masks)\n",
        "\n",
        "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(\n",
        "    train_data, sampler=train_sampler, batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
        "valid_sampler = SequentialSampler(valid_data)\n",
        "valid_dataloader = DataLoader(\n",
        "    valid_data, sampler=valid_sampler, batch_size=BATCH_SIZE\n",
        ")"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRdKSfAUY8Sk",
        "outputId": "a4a7d9a7-13df-426e-eebc-a6db6a5345e2"
      },
      "source": [
        "{tag2idx[key] : key for key in tag2idx.keys()}"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'B-LOC',\n",
              " 2: 'I-PER',\n",
              " 3: 'B-MISC',\n",
              " 4: 'I-ORG',\n",
              " 5: 'I-MISC',\n",
              " 6: 'B-ORG',\n",
              " 7: 'O',\n",
              " 8: 'I-LOC'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHqR8qhgaV5P"
      },
      "source": [
        "## Fine tune bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lynbUH3VVTYn",
        "outputId": "2c375d22-b496-4edc-f003-242df81659b5"
      },
      "source": [
        "import argparse\n",
        "import csv\n",
        "import datetime as dt\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from pytorch_transformers import BertTokenizer, BertForTokenClassification, BertConfig\n",
        "import re\n",
        "from seqeval.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import spacy\n",
        "from spacy.gold import Doc, biluo_tags_from_offsets\n",
        "import subprocess\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from tqdm import tqdm, trange\n",
        "import yaml\n",
        "\n",
        "\n",
        "\n",
        "# Constants\n",
        "label_types = LABEL_LIST\n",
        "MAX_LEN = MAX_LEN\n",
        "BATCH_SIZE = BATCH_SIZE\n",
        "EPOCHS = EPOCHS\n",
        "MODEL = 'bert-base-uncased'\n",
        "THIS_RUN = dt.datetime.now().strftime(\"%m.%d.%Y, %H.%M.%S\")\n",
        "MAX_GRAD_NORM = 1.0\n",
        "NUM_LABELS = len(label_types)+1\n",
        "FULL_FINETUNING = True\n",
        "idx2tag = {tag2idx[key] : key for key in tag2idx.keys()}\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = torch.device(\"cpu\")\n",
        "print(\"Loaded training and validation data into DataLoaders.\")\n",
        "\n",
        "# Initialize model\n",
        "model = BertForTokenClassification.from_pretrained(MODEL, num_labels=NUM_LABELS)\n",
        "model.to(device)\n",
        "print(f\"Initialized model and moved it to {device}.\")\n",
        "\n",
        "# Set hyperparameters (optimizer, weight decay, learning rate)\n",
        "optimizer_grouped_parameters = get_hyperparameters(model, FULL_FINETUNING)\n",
        "optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)\n",
        "print(\"Initialized optimizer and set hyperparameters.\")\n",
        "\n",
        "    # Fine-tune model and save checkpoint every epoch\n",
        "train_and_save_model(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    optimizer,\n",
        "    idx2tag,\n",
        "    tag2idx,\n",
        "    THIS_RUN,\n",
        "    MAX_GRAD_NORM,\n",
        "    device,\n",
        "    train_dataloader,\n",
        "    valid_dataloader)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded training and validation data into DataLoaders.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Initialized model and moved it to cpu.\n",
            "Initialized optimizer and set hyperparameters.\n",
            "Starting training loop.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}